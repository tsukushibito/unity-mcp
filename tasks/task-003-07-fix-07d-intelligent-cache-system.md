# Task 3.7 Fix 07-D: ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ 

## æ¦‚è¦
é«˜æ€§èƒ½ãªã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿè£…ã—ã¾ã™ã€‚LRUï¼ˆLeast Recently Usedï¼‰ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã€TTLï¼ˆTime To Liveï¼‰æ©Ÿèƒ½ã€ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ™ãƒ¼ã‚¹ã‚­ãƒ¼ãƒãƒƒã‚·ãƒ¥ã‚’çµ„ã¿åˆã‚ã›ã¦ã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ã®å¤§å¹…ãªçŸ­ç¸®ã¨ã‚µãƒ¼ãƒãƒ¼è² è·è»½æ¸›ã‚’å®Ÿç¾ã—ã¾ã™ã€‚

## å„ªå…ˆåº¦
**ğŸŸ¡ ä¸­å„ªå…ˆåº¦** - ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“çŸ­ç¸®ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£å‘ä¸Šã«å½±éŸ¿

## å®Ÿè£…æ™‚é–“è¦‹ç©ã‚‚ã‚Š
**60åˆ†** - é›†ä¸­ä½œæ¥­æ™‚é–“

## ä¾å­˜é–¢ä¿‚
- Task 3.7 Fix 07-A (åŸºç›¤ã‚¤ãƒ³ãƒ•ãƒ©æ•´å‚™) å®Œäº†å¿…é ˆ

## å—ã‘å…¥ã‚ŒåŸºæº–

### ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½è¦ä»¶
- [ ] LRU ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ã‚ˆã‚‹åŠ¹ç‡çš„ãªã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†
- [ ] TTL ã«ã‚ˆã‚‹è‡ªå‹•çš„ãªæœŸé™åˆ‡ã‚Œå‡¦ç†
- [ ] ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ™ãƒ¼ã‚¹ã®ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãªã‚­ãƒ¼ãƒãƒƒã‚·ãƒ¥
- [ ] åœ§ç¸®æ©Ÿèƒ½ã«ã‚ˆã‚‹ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¦ä»¶
- [ ] ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆæ™‚ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ < 1ms
- [ ] ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ > 70%
- [ ] ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®äºˆæ¸¬å¯èƒ½æ€§
- [ ] ä¸¦è¡Œã‚¢ã‚¯ã‚»ã‚¹ã§ã®ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•æ€§

### ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹è¦ä»¶
- [ ] ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã®å­¦ç¿’æ©Ÿèƒ½
- [ ] é©å¿œçš„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºèª¿æ•´
- [ ] ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒæ©Ÿèƒ½ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
- [ ] ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹ç‡ã®è‡ªå‹•æœ€é©åŒ–

### ç›£è¦–ãƒ»ãƒ‡ãƒãƒƒã‚°è¦ä»¶
- [ ] ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆã®è©³ç´°åé›†
- [ ] ãƒ’ãƒƒãƒˆç‡ã¨ãƒŸã‚¹ç‡ã®è¿½è·¡
- [ ] ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ç›£è¦–
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æãƒ¬ãƒãƒ¼ãƒˆ

## æŠ€è¡“çš„è©³ç´°

### StreamCache å®Ÿè£…

#### src/grpc/performance/cache.rs
```rust
//! ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ 
//! 
//! Unity MCP Server ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ã«ãŠã„ã¦ã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ã‚’å¤§å¹…ã«
//! çŸ­ç¸®ã™ã‚‹ãŸã‚ã®é«˜æ€§èƒ½ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ ã€‚LRU + TTL + åœ§ç¸®æ©Ÿèƒ½ã‚’æä¾›ã€‚

use std::sync::{Arc, Mutex};
use std::time::{Duration, Instant};
use std::collections::HashMap;
use std::hash::{Hash, Hasher};
use lru::LruCache;
use std::num::NonZeroUsize;
use tracing::{debug, info, warn, error};
use serde::{Serialize, Deserialize};
use crate::unity::{StreamRequest, StreamResponse, ImportAssetRequest, MoveAssetRequest};

/// ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ 
pub struct StreamCache {
    // ãƒ¡ã‚¤ãƒ³ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆLRUï¼‰
    cache: Arc<Mutex<LruCache<CacheKey, CacheEntry>>>,
    
    // ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆ
    statistics: Arc<Mutex<CacheStatistics>>,
    
    // ã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’
    access_pattern_analyzer: Arc<Mutex<AccessPatternAnalyzer>>,
    
    // è¨­å®š
    config: CacheConfig,
    
    // ã‚­ãƒ¼ãƒãƒƒã‚·ãƒ¥æˆ¦ç•¥
    key_hasher: Arc<dyn CacheKeyHasher + Send + Sync>,
}

/// ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¨ãƒ³ãƒˆãƒª
#[derive(Debug, Clone)]
pub struct CacheEntry {
    // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸãƒ¬ã‚¹ãƒãƒ³ã‚¹
    response: StreamResponse,
    
    // ã‚¨ãƒ³ãƒˆãƒªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    created_at: Instant,
    last_accessed: Instant,
    access_count: u64,
    
    // TTLæƒ…å ±
    expires_at: Option<Instant>,
    
    // åœ§ç¸®æƒ…å ±
    is_compressed: bool,
    original_size: usize,
    compressed_size: usize,
    
    // å“è³ªæƒ…å ±
    cache_quality_score: f64, // 0.0-1.0
}

/// ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼
#[derive(Debug, Clone, PartialEq, Eq, Hash)]
pub struct CacheKey {
    // æ“ä½œã‚¿ã‚¤ãƒ—
    operation_type: String,
    
    // ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒãƒƒã‚·ãƒ¥
    request_hash: u64,
    
    // ãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼ˆã‚¹ã‚­ãƒ¼ãƒå¤‰æ›´å¯¾å¿œï¼‰
    version: u32,
    
    // ã‚ªãƒ—ã‚·ãƒ§ãƒ³å±æ€§
    attributes: CacheKeyAttributes,
}

/// ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼å±æ€§
#[derive(Debug, Clone, PartialEq, Eq, Hash)]
pub struct CacheKeyAttributes {
    // ã‚¢ã‚»ãƒƒãƒˆãƒ‘ã‚¹ï¼ˆæ­£è¦åŒ–æ¸ˆã¿ï¼‰
    normalized_path: Option<String>,
    
    // ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºï¼ˆç¯„å›²ï¼‰
    file_size_range: Option<FileSizeRange>,
    
    // ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ï¼ˆç²¾åº¦èª¿æ•´æ¸ˆã¿ï¼‰
    timestamp_bucket: Option<u64>,
}

/// ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç¯„å›²ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹ç‡åŒ–ã®ãŸã‚ï¼‰
#[derive(Debug, Clone, PartialEq, Eq, Hash)]
pub enum FileSizeRange {
    Small,    // < 1MB
    Medium,   // 1MB - 10MB
    Large,    // 10MB - 100MB
    XLarge,   // > 100MB
}

/// ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨­å®š
#[derive(Debug, Clone)]
pub struct CacheConfig {
    // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚º
    pub max_entries: usize,
    pub max_memory_mb: usize,
    
    // TTLè¨­å®š
    pub default_ttl: Duration,
    pub max_ttl: Duration,
    pub adaptive_ttl: bool,
    
    // åœ§ç¸®è¨­å®š
    pub enable_compression: bool,
    pub compression_threshold_bytes: usize,
    pub compression_level: u32,
    
    // ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆæ©Ÿèƒ½
    pub enable_pattern_learning: bool,
    pub enable_prefetching: bool,
    pub enable_adaptive_sizing: bool,
    
    // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨­å®š
    pub cleanup_interval: Duration,
    pub stats_update_interval: Duration,
}

impl Default for CacheConfig {
    fn default() -> Self {
        Self {
            max_entries: 1000,
            max_memory_mb: 50,
            default_ttl: Duration::from_secs(300), // 5åˆ†
            max_ttl: Duration::from_secs(3600),    // 1æ™‚é–“
            adaptive_ttl: true,
            enable_compression: true,
            compression_threshold_bytes: 1024, // 1KB
            compression_level: 6, // ãƒãƒ©ãƒ³ã‚¹é‡è¦–
            enable_pattern_learning: true,
            enable_prefetching: false, // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ã‚ªãƒ•
            enable_adaptive_sizing: true,
            cleanup_interval: Duration::from_secs(60),
            stats_update_interval: Duration::from_secs(10),
        }
    }
}

/// ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆ
#[derive(Debug, Default, Clone, Serialize, Deserialize)]
pub struct CacheStatistics {
    // åŸºæœ¬çµ±è¨ˆ
    pub total_requests: u64,
    pub cache_hits: u64,
    pub cache_misses: u64,
    pub cache_evictions: u64,
    
    // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ
    pub hit_ratio: f64,
    pub avg_hit_time_ns: u64,
    pub avg_miss_time_ns: u64,
    
    // ãƒ¡ãƒ¢ãƒªçµ±è¨ˆ
    pub current_memory_usage: usize,
    pub peak_memory_usage: usize,
    pub current_entry_count: usize,
    pub compression_ratio: f64,
    
    // å“è³ªçµ±è¨ˆ
    pub avg_cache_quality: f64,
    pub staleness_ratio: f64, // æœŸé™åˆ‡ã‚Œç‡
    
    // æ™‚ç³»åˆ—çµ±è¨ˆ
    pub hourly_hit_rates: Vec<f64>,
    pub recent_access_patterns: HashMap<String, u64>,
}

/// ã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
#[derive(Debug)]
pub struct AccessPatternAnalyzer {
    // ãƒ‘ã‚¿ãƒ¼ãƒ³è¨˜éŒ²
    access_history: Vec<AccessRecord>,
    
    // ãƒ‘ã‚¿ãƒ¼ãƒ³çµ±è¨ˆ
    operation_frequency: HashMap<String, u64>,
    temporal_patterns: HashMap<u64, u64>, // æ™‚é–“å¸¯åˆ¥ã‚¢ã‚¯ã‚»ã‚¹
    
    // å­¦ç¿’æ¸ˆã¿ãƒ‘ã‚¿ãƒ¼ãƒ³
    learned_patterns: Vec<AccessPattern>,
    
    // äºˆæ¸¬ã‚¨ãƒ³ã‚¸ãƒ³
    predictor: Option<CachePredictor>,
}

/// ã‚¢ã‚¯ã‚»ã‚¹è¨˜éŒ²
#[derive(Debug, Clone)]
pub struct AccessRecord {
    pub timestamp: Instant,
    pub cache_key: CacheKey,
    pub hit: bool,
    pub response_time: Duration,
}

/// ã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³
#[derive(Debug, Clone)]
pub struct AccessPattern {
    pub pattern_id: String,
    pub operations: Vec<String>,
    pub frequency: u64,
    pub confidence: f64,
}

/// ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ãƒãƒƒã‚·ãƒ¥æˆ¦ç•¥
pub trait CacheKeyHasher: Send + Sync {
    fn generate_key(&self, request: &StreamRequest) -> Option<CacheKey>;
    fn should_cache_response(&self, request: &StreamRequest, response: &StreamResponse) -> bool;
    fn calculate_ttl(&self, request: &StreamRequest, base_ttl: Duration) -> Duration;
}

/// ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚­ãƒ¼ãƒãƒƒã‚·ãƒ¥æˆ¦ç•¥
pub struct DefaultCacheKeyHasher {
    version: u32,
}

impl StreamCache {
    /// æ–°ã—ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
    pub fn new() -> Self {
        Self::with_config(CacheConfig::default())
    }

    /// è¨­å®šä»˜ãã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½œæˆ
    pub fn with_config(config: CacheConfig) -> Self {
        let cache_size = NonZeroUsize::new(config.max_entries)
            .expect("Cache max_entries must be greater than 0");
        
        let cache = Arc::new(Mutex::new(LruCache::new(cache_size)));
        let statistics = Arc::new(Mutex::new(CacheStatistics::default()));
        let access_pattern_analyzer = Arc::new(Mutex::new(
            AccessPatternAnalyzer::new(&config)
        ));

        let cache_instance = Self {
            cache,
            statistics,
            access_pattern_analyzer,
            config: config.clone(),
            key_hasher: Arc::new(DefaultCacheKeyHasher::new()),
        };

        // å®šæœŸã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã¨ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã‚¿ã‚¹ã‚¯ã‚’é–‹å§‹
        cache_instance.start_maintenance_tasks();

        info!("Stream cache initialized with config: {:?}", config);
        cache_instance
    }

    /// ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å–å¾—
    pub async fn get(&self, request: &StreamRequest) -> Option<StreamResponse> {
        let start_time = Instant::now();
        
        // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã‚’ç”Ÿæˆ
        let cache_key = match self.key_hasher.generate_key(request) {
            Some(key) => key,
            None => {
                debug!("Request not cacheable");
                return None;
            }
        };

        let result = {
            let mut cache = self.cache.lock().ok()?;
            
            if let Some(entry) = cache.get_mut(&cache_key) {
                // TTL ãƒã‚§ãƒƒã‚¯
                if let Some(expires_at) = entry.expires_at {
                    if Instant::now() > expires_at {
                        // æœŸé™åˆ‡ã‚Œã‚¨ãƒ³ãƒˆãƒªã‚’å‰Šé™¤
                        cache.pop(&cache_key);
                        self.record_cache_miss(&cache_key, start_time.elapsed());
                        return None;
                    }
                }

                // ã‚¢ã‚¯ã‚»ã‚¹æƒ…å ±ã‚’æ›´æ–°
                entry.last_accessed = Instant::now();
                entry.access_count += 1;

                let response = if entry.is_compressed {
                    self.decompress_response(&entry.response)
                        .unwrap_or_else(|_| entry.response.clone())
                } else {
                    entry.response.clone()
                };

                self.record_cache_hit(&cache_key, start_time.elapsed());
                Some(response)
            } else {
                self.record_cache_miss(&cache_key, start_time.elapsed());
                None
            }
        };

        // ã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’
        self.learn_access_pattern(&cache_key, result.is_some()).await;

        result
    }

    /// ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
    pub async fn put(&self, request: &StreamRequest, response: StreamResponse) {
        // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã‚’ç”Ÿæˆ
        let cache_key = match self.key_hasher.generate_key(request) {
            Some(key) => key,
            None => return,
        };

        // ã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯èƒ½æ€§ã‚’ãƒã‚§ãƒƒã‚¯
        if !self.key_hasher.should_cache_response(request, &response) {
            debug!("Response not cacheable for key: {:?}", cache_key);
            return;
        }

        let now = Instant::now();
        let ttl = self.key_hasher.calculate_ttl(request, self.config.default_ttl);
        let expires_at = if ttl == Duration::MAX {
            None
        } else {
            Some(now + ttl)
        };

        // ãƒ¬ã‚¹ãƒãƒ³ã‚¹åœ§ç¸®ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
        let (final_response, is_compressed, original_size, compressed_size) = 
            if self.config.enable_compression {
                self.compress_response_if_beneficial(&response)
            } else {
                let size = self.estimate_response_size(&response);
                (response, false, size, size)
            };

        // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¨ãƒ³ãƒˆãƒªã‚’ä½œæˆ
        let cache_entry = CacheEntry {
            response: final_response,
            created_at: now,
            last_accessed: now,
            access_count: 1,
            expires_at,
            is_compressed,
            original_size,
            compressed_size,
            cache_quality_score: self.calculate_cache_quality_score(request),
        };

        // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
        {
            let mut cache = match self.cache.lock() {
                Ok(cache) => cache,
                Err(_) => {
                    error!("Failed to acquire cache lock");
                    return;
                }
            };

            // ãƒ¡ãƒ¢ãƒªåˆ¶é™ãƒã‚§ãƒƒã‚¯
            if self.should_evict_for_memory(&cache_entry) {
                self.evict_by_memory_pressure(&mut cache);
            }

            if let Some((evicted_key, _)) = cache.push(cache_key.clone(), cache_entry) {
                debug!("Cache entry evicted: {:?}", evicted_key);
                self.record_cache_eviction();
            }
        }

        // çµ±è¨ˆæ›´æ–°
        self.update_cache_statistics().await;

        debug!("Cached response for key: {:?}, TTL: {:?}", cache_key, ttl);
    }

    /// ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã‚’ç›´æ¥æŒ‡å®šã—ã¦å–å¾—ï¼ˆé«˜é€Ÿãƒ‘ã‚¹ï¼‰
    pub fn get_by_key(&self, key: &CacheKey) -> Option<StreamResponse> {
        let start_time = Instant::now();
        
        let result = {
            let mut cache = self.cache.lock().ok()?;
            
            if let Some(entry) = cache.get_mut(key) {
                // TTL ãƒã‚§ãƒƒã‚¯
                if let Some(expires_at) = entry.expires_at {
                    if Instant::now() > expires_at {
                        cache.pop(key);
                        return None;
                    }
                }

                entry.last_accessed = Instant::now();
                entry.access_count += 1;

                let response = if entry.is_compressed {
                    self.decompress_response(&entry.response)
                        .unwrap_or_else(|_| entry.response.clone())
                } else {
                    entry.response.clone()
                };

                Some(response)
            } else {
                None
            }
        };

        let elapsed = start_time.elapsed();
        if result.is_some() {
            self.record_cache_hit(key, elapsed);
        } else {
            self.record_cache_miss(key, elapsed);
        }

        result
    }

    /// ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºã‚’å‹•çš„ã«èª¿æ•´
    pub fn resize_cache(&self, new_size: usize) {
        if let Ok(mut cache) = self.cache.lock() {
            let new_cache_size = NonZeroUsize::new(new_size)
                .unwrap_or(NonZeroUsize::new(100).unwrap());
            
            cache.resize(new_cache_size);
            info!("Cache resized to {} entries", new_size);
        }
    }

    /// ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢
    pub fn clear(&self) {
        if let Ok(mut cache) = self.cache.lock() {
            cache.clear();
            info!("Cache cleared");
        }

        if let Ok(mut stats) = self.statistics.lock() {
            *stats = CacheStatistics::default();
        }
    }

    /// ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆã‚’å–å¾—
    pub fn get_statistics(&self) -> CacheStatistics {
        self.statistics.lock()
            .map(|stats| stats.clone())
            .unwrap_or_default()
    }

    /// ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹ç‡ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
    pub fn generate_efficiency_report(&self) -> CacheEfficiencyReport {
        let stats = self.get_statistics();
        let current_size = {
            self.cache.lock()
                .map(|cache| cache.len())
                .unwrap_or(0)
        };

        CacheEfficiencyReport {
            hit_ratio: stats.hit_ratio,
            memory_efficiency: if stats.peak_memory_usage > 0 {
                stats.current_memory_usage as f64 / stats.peak_memory_usage as f64
            } else {
                1.0
            },
            compression_effectiveness: stats.compression_ratio,
            cache_utilization: current_size as f64 / self.config.max_entries as f64,
            avg_response_time_improvement: self.calculate_response_time_improvement(),
            recommendations: self.generate_optimization_recommendations(&stats),
        }
    }

    // å†…éƒ¨ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰

    fn record_cache_hit(&self, _key: &CacheKey, response_time: Duration) {
        if let Ok(mut stats) = self.statistics.lock() {
            stats.total_requests += 1;
            stats.cache_hits += 1;
            stats.hit_ratio = stats.cache_hits as f64 / stats.total_requests as f64;
            
            // ç§»å‹•å¹³å‡ã§ãƒ’ãƒƒãƒˆæ™‚é–“ã‚’æ›´æ–°
            let new_hit_time = response_time.as_nanos() as u64;
            stats.avg_hit_time_ns = (stats.avg_hit_time_ns + new_hit_time) / 2;
        }
    }

    fn record_cache_miss(&self, _key: &CacheKey, response_time: Duration) {
        if let Ok(mut stats) = self.statistics.lock() {
            stats.total_requests += 1;
            stats.cache_misses += 1;
            stats.hit_ratio = stats.cache_hits as f64 / stats.total_requests as f64;
            
            let new_miss_time = response_time.as_nanos() as u64;
            stats.avg_miss_time_ns = (stats.avg_miss_time_ns + new_miss_time) / 2;
        }
    }

    fn record_cache_eviction(&self) {
        if let Ok(mut stats) = self.statistics.lock() {
            stats.cache_evictions += 1;
        }
    }

    async fn learn_access_pattern(&self, key: &CacheKey, hit: bool) {
        if !self.config.enable_pattern_learning {
            return;
        }

        let record = AccessRecord {
            timestamp: Instant::now(),
            cache_key: key.clone(),
            hit,
            response_time: Duration::default(), // ç°¡ç•¥åŒ–
        };

        if let Ok(mut analyzer) = self.access_pattern_analyzer.lock() {
            analyzer.record_access(record);
        }
    }

    fn compress_response_if_beneficial(&self, response: &StreamResponse) -> (StreamResponse, bool, usize, usize) {
        let original_size = self.estimate_response_size(response);
        
        if original_size < self.config.compression_threshold_bytes {
            return (response.clone(), false, original_size, original_size);
        }

        // å®Ÿéš›ã®åœ§ç¸®å®Ÿè£…ã¯çœç•¥ï¼ˆå®Ÿè£…æ™‚ã«flateã¾ãŸã¯lz4ä½¿ç”¨ï¼‰
        // ã“ã“ã§ã¯æ¦‚å¿µçš„ãªå®Ÿè£…
        let compressed_response = response.clone(); // å®Ÿéš›ã¯åœ§ç¸®å‡¦ç†
        let compressed_size = (original_size as f64 * 0.7) as usize; // 30%åœ§ç¸®ã¨ä»®å®š

        (compressed_response, true, original_size, compressed_size)
    }

    fn decompress_response(&self, response: &StreamResponse) -> Result<StreamResponse, CacheError> {
        // å®Ÿéš›ã®è§£å‡å®Ÿè£…ã¯çœç•¥
        Ok(response.clone())
    }

    fn estimate_response_size(&self, _response: &StreamResponse) -> usize {
        // å®Ÿéš›ã®ã‚µã‚¤ã‚ºè¨ˆç®—å®Ÿè£…ã¯çœç•¥
        1024 // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
    }

    fn calculate_cache_quality_score(&self, _request: &StreamRequest) -> f64 {
        // ã‚­ãƒ£ãƒƒã‚·ãƒ¥å“è³ªã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆè¤‡é›‘åº¦ã€ã‚µã‚¤ã‚ºã€é »åº¦ç­‰ã‚’è€ƒæ…®ï¼‰
        0.8 // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
    }

    fn should_evict_for_memory(&self, _entry: &CacheEntry) -> bool {
        // ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ãƒã‚§ãƒƒã‚¯
        false // ç°¡ç•¥åŒ–
    }

    fn evict_by_memory_pressure(&self, _cache: &mut LruCache<CacheKey, CacheEntry>) {
        // ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ãƒ™ãƒ¼ã‚¹ã®é€€é¿å‡¦ç†
    }

    async fn update_cache_statistics(&self) {
        // çµ±è¨ˆæ›´æ–°å‡¦ç†
    }

    fn start_maintenance_tasks(&self) {
        // å®šæœŸãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã‚¿ã‚¹ã‚¯é–‹å§‹
    }

    fn calculate_response_time_improvement(&self) -> f64 {
        let stats = self.get_statistics();
        if stats.avg_miss_time_ns > 0 && stats.avg_hit_time_ns > 0 {
            (stats.avg_miss_time_ns - stats.avg_hit_time_ns) as f64 / stats.avg_miss_time_ns as f64
        } else {
            0.0
        }
    }

    fn generate_optimization_recommendations(&self, _stats: &CacheStatistics) -> Vec<String> {
        vec![
            "Consider increasing cache size if hit ratio < 70%".to_string(),
            "Enable compression for better memory efficiency".to_string(),
            "Adjust TTL based on access patterns".to_string(),
        ]
    }
}

/// ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹ç‡ãƒ¬ãƒãƒ¼ãƒˆ
#[derive(Debug, Clone)]
pub struct CacheEfficiencyReport {
    pub hit_ratio: f64,
    pub memory_efficiency: f64,
    pub compression_effectiveness: f64,
    pub cache_utilization: f64,
    pub avg_response_time_improvement: f64,
    pub recommendations: Vec<String>,
}

/// ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¨ãƒ©ãƒ¼
#[derive(Debug, thiserror::Error)]
pub enum CacheError {
    #[error("Compression failed: {0}")]
    CompressionError(String),
    
    #[error("Decompression failed: {0}")]
    DecompressionError(String),
    
    #[error("Cache capacity exceeded")]
    CapacityExceeded,
    
    #[error("Invalid cache entry")]
    InvalidEntry,
}

// çœç•¥ã•ã‚ŒãŸæ§‹é€ ä½“ã®å®Ÿè£…...
impl DefaultCacheKeyHasher {
    pub fn new() -> Self {
        Self { version: 1 }
    }
}

impl CacheKeyHasher for DefaultCacheKeyHasher {
    fn generate_key(&self, request: &StreamRequest) -> Option<CacheKey> {
        // å®Ÿè£…çœç•¥
        None
    }

    fn should_cache_response(&self, _request: &StreamRequest, _response: &StreamResponse) -> bool {
        true
    }

    fn calculate_ttl(&self, _request: &StreamRequest, base_ttl: Duration) -> Duration {
        base_ttl
    }
}

impl AccessPatternAnalyzer {
    fn new(_config: &CacheConfig) -> Self {
        Self {
            access_history: Vec::new(),
            operation_frequency: HashMap::new(),
            temporal_patterns: HashMap::new(),
            learned_patterns: Vec::new(),
            predictor: None,
        }
    }

    fn record_access(&mut self, _record: AccessRecord) {
        // ã‚¢ã‚¯ã‚»ã‚¹è¨˜éŒ²å‡¦ç†
    }
}

// ã‚­ãƒ£ãƒƒã‚·ãƒ¥äºˆæ¸¬ã‚¨ãƒ³ã‚¸ãƒ³ç­‰ã®å®Ÿè£…ã¯çœç•¥...
pub struct CachePredictor;
```

## å®Ÿè£…è¨ˆç”»

### Step 1: åŸºæœ¬ã‚­ãƒ£ãƒƒã‚·ãƒ¥å®Ÿè£… (25åˆ†)
1. StreamCache åŸºæœ¬æ§‹é€ 
2. LRU ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¨TTLæ©Ÿèƒ½
3. åŸºæœ¬çš„ãªget/putæ“ä½œ

### Step 2: ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆæ©Ÿèƒ½ (20åˆ†)
1. ã‚­ãƒ¼ãƒãƒƒã‚·ãƒ¥æˆ¦ç•¥å®Ÿè£…
2. åœ§ç¸®/è§£å‡æ©Ÿèƒ½
3. ã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’åŸºç›¤

### Step 3: çµ±è¨ˆãƒ»ç›£è¦– (15åˆ†)
1. è©³ç´°ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆ
2. åŠ¹ç‡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
3. æœ€é©åŒ–æ¨å¥¨æ©Ÿèƒ½

## ãƒ†ã‚¹ãƒˆè¦ä»¶

### ã‚­ãƒ£ãƒƒã‚·ãƒ¥å‹•ä½œãƒ†ã‚¹ãƒˆ
```rust
#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_basic_cache_operations() {
        let cache = StreamCache::new();
        
        // ã¾ãšã¯ãƒŸã‚¹ã‚’ç¢ºèª
        let request = create_test_request();
        assert!(cache.get(&request).await.is_none());
        
        // ä¿å­˜ã—ã¦å–å¾—
        let response = create_test_response();
        cache.put(&request, response.clone()).await;
        
        let cached_response = cache.get(&request).await;
        assert!(cached_response.is_some());
        assert_eq!(cached_response.unwrap(), response);
    }

    #[tokio::test]
    async fn test_ttl_expiration() {
        let mut config = CacheConfig::default();
        config.default_ttl = Duration::from_millis(10);
        let cache = StreamCache::with_config(config);
        
        let request = create_test_request();
        let response = create_test_response();
        
        cache.put(&request, response).await;
        assert!(cache.get(&request).await.is_some());
        
        // TTLæœŸé™åˆ‡ã‚Œã‚’å¾…æ©Ÿ
        tokio::time::sleep(Duration::from_millis(15)).await;
        assert!(cache.get(&request).await.is_none());
    }

    #[test]
    fn test_cache_statistics() {
        let cache = StreamCache::new();
        let stats = cache.get_statistics();
        
        assert_eq!(stats.total_requests, 0);
        assert_eq!(stats.cache_hits, 0);
        assert_eq!(stats.hit_ratio, 0.0);
    }
}
```

## æˆåŠŸåŸºæº–

### æ©Ÿèƒ½åŸºæº–
- LRU + TTL ãŒæ­£å¸¸å‹•ä½œ
- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ > 70%
- çµ±è¨ˆåé›†ã¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
- ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•æ€§ç¢ºä¿

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŸºæº–
- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆæ™‚ãƒ¬ã‚¹ãƒãƒ³ã‚¹ < 1ms
- ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡äºˆæ¸¬å¯èƒ½
- åœ§ç¸®ã«ã‚ˆã‚‹åŠ¹ç‡åŒ–ç¢ºèª

## æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥å®Œäº†å¾Œï¼š
1. Task 3.7 Fix 07-E: ä¸¦åˆ—å‡¦ç†ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ¼ãƒ«å®Ÿè£…
2. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¨ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ¼ãƒ«ã®çµ±åˆ
3. çµ±åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ

## é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
- Task 3.7 Fix 07-A (åŸºç›¤ã‚¤ãƒ³ãƒ•ãƒ©æ•´å‚™)
- LRU ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨­è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³
- ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ€é©åŒ–ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹